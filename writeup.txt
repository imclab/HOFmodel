--------------------------------------------------

INTRODUCTION

--------------------------------------------------


We're going to attempt to predict who will get into the Baseball Hall of Fame this year using a statistical model based on past data. Specifically, we will predict exactly what percentage of the vote each of this year's 36 eligible players will receive, and we'll provide prediction intervals, to describe the uncertainty of our forecasts.

First, a quick review of the Baseball Hall of Fame (HOF) voting rules:

1. Who are the voters?

The voters are members of the Baseball Writers Association of America (BBWAA). The number of ballots sent out each year has grown slowly from about 300 ballots fifty years ago to about 600 ballots today. Each voter receives a ballot (where in a typical year about 40 eligible players are listed), and can select up to 10 players on his or her ballot that they think should be inducted into the Hall of Fame (but no more than 10). A voter can also return an empty ballot (selecting no players at all).

2. Which players are eligible to be on the ballot?

- Only players who have been retired for at least 5 years, and who played at least 10 seasons in the major leagues are eligible to be listed on the ballot.
- If a player is selected on more than 75% of the ballots in any year, he is inducted into the Hall of Fame.
- If a player is selected on fewer than 5% of the ballots in any year, he is removed from further consideration forever.
- If a player is selected on between 5% and 75% of the ballots in a given year, he will be eligible again the following year, unless he has already appeared on the ballot 15 times, after which time he is no longer eligible.

3. What does the historical data look like?

Glad you asked! My colleague, Carlos Scheidegger, and I created an interactive visualization of historical voting records using data obtained (mostly) from baseball-reference.com. The most interesting players to visualize (out of the 1070 total players who have ever received a HOF vote since voting began in 1936) are those that appear on the ballot in multiple years, because their voting "trajectories" take on a variety of zigzag shapes between 5% and 75% on the y-axis:

http://cscheid.net/static/mlb-hall-of-fame-voting/

This interactive viz prompted us to wonder how accurately we could predict the results of an upcoming election, and this is what we set out to do today.


--------------------------------------------------

OUR MODELING STRATEGY

--------------------------------------------------

Our idea is to fit statistical models to historical voting data to estimate the relationship between a player's career statistics and his Hall of Fame voting percentage(s). We'll fit two basic types of models:

1. For players who are appearing on the ballot for the first time, we'll predict their first-ballot voting percentage using their career statistics (using different statistics, of course, depending on whether they were a pitcher or a position player).

2. For players from last year's ballot who are re-appearing on this year's ballot (meaning their voting percentage from the previous year was between 5% and 75%, and they have not yet reached their maximum of 15 years on the ballot), we will predict their voting percentage as a function of their previous year's voting percentage and a few other variables (but not their career statistics -- the idea being that their past voting history is by far the strongest predictor of their future voting outcomes).

The basic challenge in fitting both types of models will be to use the most relevant statistics that we can find, in order to explain as much variation in HOF voting as possible. An interesting question that this analysis will try to answer is "How much of a player's HOF voting percentage is related to his career statistics, and how much is related to other, harder-to-measure qualities, like his overall popularity, or any other unmeasurable qualities that influence voters?"

In the next few pages, we'll take you through our analysis, describing the progression of different statistical models that we used and explaining how we devised them. The measure of predictive accuracy that we will use is RMSE, which stands for "Root Mean Squared Error". It is probably the most common statistical measure of predictive accuracy. When we say that a particular statistical model has an RMSE of 10%, in this context, this means that for a given prediction, the actual voting percentage will be within 20% of the predicted voting percentage (20% being 2 times the RMSE) about 95% of the time. So the "margin of error" for such a prediction would be +/- 20%.



--------------------------------------------------

THE DATA

--------------------------------------------------

Since HOF voting began in 1936, there have been 1070 different players listed on the ballots, and through 2013, 107 of them have been inducted into the Hall of Fame by being selected on 75% or more of BBWAA ballots. The voting rules have changed somewhat since 1936, but have been relatively stable since 1967. So, for this analysis, we will only use data from players whose first appearance on the ballot occurred in 1967 or afterward, giving us 47 years worth of training data and 635 unique players in the data set (406 position players and 229 pitchers). Including multiple appearances on the ballot, the total number of player-years in which we observe a voting percentage is 1458 (an average of about 2.3 years on the ballot per player).

To measure our predictive accuracy for different models, we will make one-year-ahead predictions starting in 1997, and going through 2013. That is, using data from 1967-1996, we will fit a model and make predictions for the 1997 ballot. Then we'll update the model by training it on data from 1967-1997, and we'll make predictions for the 1998 ballot, and so on, through 2013. This will give us 17 years of "out-of-sample" predictions with which to measure how accurate our models are. The choice to start with 1997 is just based on having the round number of 30 years as the minimum number of years of training data (since any statistical model needs a decent amount of data to "warm up" or "burn in").



--------------------------------------------------

THE BASELINE MODEL

--------------------------------------------------

The first model we fit uses a player's basic career statistics to predict his first-year voting percentage, and for subsequent years, we simply predict that a player will receive the same voting percentage as he did in his previous year on the ballot. This model is meant as a baseline model, which we'll subsequently improve.

The career statistics we used were:

For batters: Yrs, G, AB, R, H, HR, RBI, SB, BB, BA, OBP, SLG, OPS.Plus

For pitchers: Yrs, W, L, ERA, ERA.Plus, WHIP, G, GS, SV, IP, H, HR, BB, SO

For pitchers, hits (H), home runs (HR), and walks (BB) are the number of these that the pitcher allowed during their career (where more is obviously worse), whereas for batters, these statistics are how many the batter accumulated during his career. "OPS.Plus" and "ERA.Plus" are variations of OPS (OBP + SLG) and ERA (earned run average) that attempt to account for how a player compared to the rest of the league in a given season. "GS" stands for "Games Started" by a pitcher.

In this basic model we also include dummy variables for the player's position (if he is not a pitcher).

We fit a logistic regression model, where the model says that log(p/(1-p)) = B0 + B1*X1 + B2*X2 + ... + Bp*Xp. Here, p is the percentage of ballots on which the player is selected, X1, X2, ... are the career statistics, or predictor variables, for each player, and B0, B1, ... are the regression coefficients, or linear weights, that we are estimating from the training data. The point is to learn from historical training data what values of B0, B1, ... give the most accurate predictions of p.

When we fit this model to the data from 1967 - 1996, for batters, we get the following values of B0, B1, etc.:

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
(Intercept)   -4.949367   0.057029 -86.787  < 2e-16 ***
x.matYrs       0.454624   0.060458   7.520 5.49e-14 ***
x.matG         1.242117   0.199652   6.221 4.93e-10 ***
x.matAB       -4.771602   0.503263  -9.481  < 2e-16 ***
x.matR         2.612957   0.152765  17.104  < 2e-16 ***
x.matH         3.870655   0.537213   7.205 5.80e-13 ***
x.matHR        0.873973   0.119409   7.319 2.50e-13 ***
x.matRBI      -0.838747   0.123516  -6.791 1.12e-11 ***
x.matSB        0.004855   0.024552   0.198    0.843    
x.matBB        0.096716   0.113228   0.854    0.393    
x.matBA        0.166626   0.155027   1.075    0.282    
x.matOBP      -1.213454   0.138618  -8.754  < 2e-16 ***
x.matSLG       0.303809   0.146421   2.075    0.038 *  
x.matOPS.Plus  0.597417   0.107547   5.555 2.78e-08 ***
x.matX1B       1.341920   0.097655  13.741  < 2e-16 ***
x.matRF        1.126763   0.092814  12.140  < 2e-16 ***
x.matLF        1.119381   0.096533  11.596  < 2e-16 ***
x.matCF        0.656748   0.095743   6.859 6.91e-12 ***
x.matC         1.919993   0.096982  19.797  < 2e-16 ***
x.matX3B       1.181849   0.090670  13.035  < 2e-16 ***
x.matX2B       1.336329   0.091622  14.585  < 2e-16 ***
x.matSS        1.618345   0.093989  17.218  < 2e-16 ***
x.matDH        0.277919   0.061834   4.495 6.97e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

The values in the column labeled "Estimate" are the values of B0, B1, ... that explained the training data the best. Don't worry about interpreting their values -- it's hard, given that it's a logistic regression model, and that we scaled the input variables to have a mean of zero and an sd of 1. Just focus on the values in the column labeled "z value" and their signs. Here we see that runs (R) was one of the strongest positive predictors of voting percentage, because of its high, positive z-value. The 9 positions included in the model here all have positive regression coefficients, because they are measured relative to the baseline position, which is "OF" (an old, generic position called "outfield" for a few players who played various outfield positions, and weren't assigned to just one). Note that Catchers (C) have the highest coefficient among positions, and shortstops (SS) are the next-highest. This reflects the well-known fact that these two positions have different standards for Hall of Fame voting -- a shortstop or catcher with the same offensive career statistics as a right fielder, for example, would get a higher voting percentage, presumably because SS and C are more difficult defensive positions to play. For the same reason, the Designated Hitter position (DH) has the lowest coefficient.

The big take-away here is (1) most of the signs of the coefficients make sense, and (2) almost all of the predictor variables have highly significant coefficients. This means that these variables are useful in predicting the outcome, and we probably have enough data to add more variables to the model and measure their coefficients, too.

Now that we have fit this model to all batters who made their first appearance on the ballot between 1967 - 1996, we use the model to make predictions for 1997. In 1997, there were 6 batters on the ballot for the first time: Dave Parker, Dwight Evans, Ken Griffey Sr., Garry Templeton, Terry Kennedy, and Terry Puhl. Our predicted voting percentages for these 6 batters, based on their career statistics and the model we just fit, are in the table below, next to the actual voting percentage for each one.

              Name   Prediction      Actual
1      Dave Parker        0.369       0.175
2     Dwight Evans        0.483       0.059
3  Ken Griffey Sr.        0.116       0.046
4  Garry Templeton        0.056       0.004
5    Terry Kennedy        0.004       0.002
6       Terry Puhl        0.002       0.002

These predictions were pretty bad -- the model was off by about 20% for Dave Parker, and by about 43% for Dwight Evans! The model seemed to overestimate almost everybody's percentage. Perhaps for some reason these 6 players had relatively impressive career statistics, but were not popular with writers, or were not considered great players relative to their peers, for some reason other than their statistics.

The rmse for these 6 predictions is:

RMSE = sqrt((0.369 - 0.175)^2 + (0.483 - 0.059)^2 + ... + (0.002 - 0.002)^2)
     = 0.163,

or 16.3%. That's pretty bad. That means our margins of error would be about +/- 32%. If we don't use any variables at all, we have a baseline rmse of about 24%. So reducing it to 16.3% is OK, but we can do better. (And of course, this is only for a tiny subset of 6 players).

We fit the baseline model for pitchers appearing on the ballot for the first time, also (based on their career pitching statistics).

And in this baseline model, as mentioned before, for returning players on the ballot, we simply use their previous year's voting percentage as their current prediction.

When we fit the baseline model and make one-year-ahead predictions for each year from 1997 - 2013, we make a total of 498 predictions (about 29 per year). The overall rmse of these predictions is 11.0%. (which means that the six predictions illustrated above were less accurate than average). This is our baseline rmse.

Let's pause to make our first prediction for the 2014 class. According to the baseline model, the 36 players on the ballot this year will receive the following voting percentage (with a margin of error of about +/- 22%, or twice the rmse):

              Name Predicted
1     Craig Biggio      68.2
2      Jack Morris      67.7
3     Jeff Bagwell      59.6
4      Mike Piazza      57.8
5       Tim Raines      52.2
6        Lee Smith      47.8
7   Curt Schilling      38.8
8    Roger Clemens      37.6
9      Barry Bonds      36.2
10  Edgar Martinez      35.9
11   Alan Trammell      33.6
12    Larry Walker      21.6
13    Fred McGriff      20.7
14    Mark McGwire      16.9
15   Don Mattingly      13.2
16      Sammy Sosa      12.5
17 Rafael Palmeiro       8.8
18     Greg Maddux       9.9
19    Frank Thomas      30.5
20    Mike Mussina       7.6
21     Tom Glavine      10.6
22       Jeff Kent      31.0
23    Kenny Rogers       0.2
24   Luis Gonzalez       7.4
25     Moises Alou       4.3
26      Ray Durham       3.6
27      Hideo Nomo       0.1
28   Richie Sexson       0.2
29    Paul Lo Duca       0.2
30 Armando Benitez       1.0
31     Mike Timlin       0.0
32      Sean Casey       0.3
33    Jacque Jones       0.0
34      Eric Gagne       0.7
35       J.T. Snow       0.1
36      Todd Jones       0.0

Wow! Those are some incredibly low predictions for first-timers Greg Maddux, Frank Thomas, and Tom Glavine. Most experts think that Maddux will get above 90% of the vote, and Glavine and Thomas will be in the 70% range. It's possible that Maddux's career numbers simply don't capture what a dominant pitcher he was throughout his career compared to his peers. Hopefully we'll see this prediction rise a lot using the next few models. (Hint: we will, because of a little lurking variable called 'Steroids').



--------------------------------------------------

BUILDING THE NEXT MODEL

--------------------------------------------------

To investigate which variables we should add to the next model, it's helpful to analyze the residuals from this model, where the residual is defined as the observed voting percentage - the predicted voting percentage. In particular, let's see which players had the highest residuals (they received a much higher voting percentage than we predicted), and which players had the lowest residuals (they received a much lower voting percentage than we predicted).

First, the highest residuals:

  Year           Name Actual Predicted Residual
1 2002    Ozzie Smith   91.7       8.8     82.9
2 2001  Kirby Puckett   82.1       2.3     79.8
3 2005     Wade Boggs   91.9      56.7     35.1
4 2004   Paul Molitor   85.2      50.8     34.4
5 2010 Edgar Martinez   36.2       6.3     29.9

I see two predictors that should improve the predictions for Ozzie Smith and Kirby Puckett: All-Star games and Gold Gloves. Both of these players were popular (i.e. they went to lots of All-Star games), and were excellent fielders (so they won lots of Gold Glove awards). Including these variables for all players as additional predictors should increase our predicted voting percentages for Smith and Puckett, thereby decreasing their residuals and lowering the overall rmse.

What about the lowest residuals from the baseline model?

  Year            Name Actual Predicted Residual
1 2011 Rafael Palmeiro   11.0      88.6    -77.6
2 2013     Barry Bonds   36.2      99.5    -63.3
3 2013   Roger Clemens   37.6      98.7    -61.1
4 2013    Julio Franco    1.1      48.4    -47.4
5 1997    Dwight Evans    5.9      48.3    -42.4

A-ha. There is an obvious variable that will improve the predictions for the 3 players with the smallest residuals, too: association with steroids. Palmeiro, Bonds, and Clemens are all associated with the steroid scandal in baseball. If there is an objective variable measuring steroid association, it should help immensely. Fortunately, there are two:

1. A player's appearance on the Mitchell Report (the famous report by George Mitchell on performance-enhancing drugs in baseball). There were 87 players named in the Mitchell Report (for various steroid-related incidents), and Bonds and Clemens were two of them. A total of 18 of the 87 have appeared on the HOF ballot between 1967 and 2014.

2. The record of whether a player was ever suspended by the league for failing a drug test. There have been 39 different players suspended by MLB for drug test failures, and one of them is Rafael Palmeiro. He is the only one to have appeared on the HOF ballot from 1967 - 2014.

We'll incorportate All-Star appearances, Gold Gloves, and association with the steroid scandal in our next model.

Last, we also note here that the average residual among the 262 voting percentage predictions in which a player had already appeared on at least one ballot was 1.8%. In other words, on average, a player's vote percentage goes up on subsequent ballots. This is fairly obvious from looking at the interactive viz. What it means is that we can also improve our predictions by fitting a more complicated model for returning players. We'll get to that a bit later.

To see the entire residual plot for the baseline model, see the .pdf file "fig_residuals_M0.pdf". [to be included].



--------------------------------------------------

MODEL 1.0:

--------------------------------------------------

To incorporate Al-Star appearances, we compute the percentage of years of each player's career that he was invited to the All-Star Game (it doesn't matter if he actually played in the game -- just whether he was on the roster). We also collected the number of Gold Glove Awards for each player (reminder: this award is for excellent fielding), and coded it as a 4-level categorical variable:

1 = 0 Gold Gloves
2 = 1 Gold Glove
3 = 2-5 Gold Gloves
4 = 6 or more Gold Gloves

Greg Maddux is the all-time leader in MLB with 18 gold gloves (for being the best-fielding pitcher in his league).

We coded association with the steroid scandal as an indicator variable that we'll call 'Steroids' where a player has a value of 1 if he was either named in the Mitchell Report or was suspended by MLB for a failed drug test, and a value of 0 otherwise.

The coefficients of the new model for batters, for example, using data from 1967 - 2013, is as follows:

Coefficients:
                Estimate Std. Error  z value Pr(>|z|)    
(Intercept)     -5.08017    0.04366 -116.347  < 2e-16 ***
x.matYrs         0.42724    0.03583   11.924  < 2e-16 ***
x.matG           0.26987    0.14892    1.812 0.069955 .  
x.matAB          1.16978    0.39679    2.948 0.003198 ** 
x.matR           1.20192    0.09396   12.792  < 2e-16 ***
x.matH          -0.93317    0.38502   -2.424 0.015363 *  
x.matHR          0.28366    0.08002    3.545 0.000393 ***
x.matRBI        -0.20865    0.07667   -2.721 0.006499 ** 
x.matSB          0.04000    0.01941    2.061 0.039332 *  
x.matBB         -0.11974    0.07773   -1.541 0.123434    
x.matBA          0.79998    0.10883    7.351 1.97e-13 ***
x.matOBP        -0.64217    0.09466   -6.784 1.17e-11 ***
x.matSLG        -0.50506    0.09638   -5.240 1.60e-07 ***
x.matOPS.Plus    1.22115    0.05915   20.646  < 2e-16 ***
x.matX1B         0.99950    0.09038   11.059  < 2e-16 ***
x.matRF          0.68835    0.08946    7.694 1.42e-14 ***
x.matLF          0.86928    0.08675   10.020  < 2e-16 ***
x.matCF          0.65743    0.08656    7.595 3.07e-14 ***
x.matC           0.96929    0.08338   11.626  < 2e-16 ***
x.matX3B         0.78039    0.08181    9.539  < 2e-16 ***
x.matX2B         0.71355    0.07884    9.051  < 2e-16 ***
x.matSS          0.90907    0.07781   11.683  < 2e-16 ***
x.matDH          0.46369    0.04403   10.532  < 2e-16 ***
x.matAS.percent  1.08997    0.01724   63.236  < 2e-16 ***
x.matdrugs      -0.96141    0.02753  -34.923  < 2e-16 ***
x.matgold1       0.08947    0.01294    6.916 4.63e-12 ***
x.matgold2       0.09581    0.01357    7.060 1.67e-12 ***
x.matgold3       0.23501    0.01171   20.070  < 2e-16 ***

As you can see, the new variables are all highly statistically significant, and their signs are just as we would expect.

The predictions for first-ballot players in 2014 also seem to have improved (at least according to our personal expectations). Greg Maddux suddenly has a very high predicted percentage, for example. This is because Roger Clemens is no longer de-valuing great career statistics, since 'Steroids' now explains a large part of his low first-year voting percentage.

18     Greg Maddux      84.4
19    Frank Thomas      45.7
20    Mike Mussina      51.1
21     Tom Glavine      44.2
22       Jeff Kent       9.1
23    Kenny Rogers       2.0
24   Luis Gonzalez      11.3
25     Moises Alou       7.7
26      Ray Durham       0.7
27      Hideo Nomo       0.1
28   Richie Sexson       0.1
29    Paul Lo Duca       0.0
30 Armando Benitez       1.1
31     Mike Timlin       0.1
32      Sean Casey       0.3
33    Jacque Jones       0.0
34      Eric Gagne       0.0
35       J.T. Snow       0.2
36      Todd Jones       0.2

The largest and smallest residuals are a little different now, but they contain some of the same players as before:

Largest 5 residuals:

  Year          Name Actual Predicted Residual
1 1999   Robin Yount   77.5       7.4     70.0
2 2001 Kirby Puckett   82.1      19.4     62.7
3 2004  Paul Molitor   85.2      42.4     42.8
4 2005    Wade Boggs   91.9      58.7     33.2
5 1999  George Brett   98.2      65.8     32.4

Smallest 5 residuals:

  Year          Name Actual Predicted Residual
1 2013   Barry Bonds   36.2      99.8    -63.6
2 2013 Roger Clemens   37.6      97.1    -59.5
3 2008    Tim Raines   24.3      82.9    -58.6
4 2007  Jose Canseco    1.1      46.8    -45.7
5 2007  Mark McGwire   23.5      68.7    -45.2

You'll notice that the smallest residuals still contain Bonds and Clemens. This is unfortunate, but it's not a mistake in the modeling: Remember, these residuals are from *one-year-ahead* predictions, or what are known as "out-of-sample" predictions.

One problem with the 'Steroids' variable is that the players associated with the steroids scandal have had better career statistics as the years have progressed. For example, Jose Canseco, who was named in the Mitchell Report, appeared on the HOF ballot for the first time in 2007. His career statistics weren't that great, so the estimated 'Steroids' effect was not very large (it was -0.07 after Canseco's results were included in the model). Then Rafael Palmeiro appeared on the ballot in 2011, and his career statistics were much better than Canseco's, so the estimated 'Steroids' effect was much larger than before (Palmeiro was selected on only 11% of ballots -- the 'Steroids' effect dropped to -0.27 after his voting percentage was included in the model). But Roger Clemens and Barry Bonds have *fantastic* career statistics, and they didn't appear on the ballot until 2013. So it was only after the 2013 voting results were released that we *truly* learned how large the 'Steroids' effect was, when Roger Clemens and Barry Bonds were selected on only 36% of ballots in their first year. For batters, the 'Steroids' effect dropped from about -0.27 to -0.96, and for pitchers it dropped from about -0.05 to -0.54. One would hope that by now, we have observed the full range of career statistics among steroid-tainted players, and our model has accurately captured its effect. But of course only time will tell...

Anyways, turning to the positive residuals: these 5 players are all contact hitters with high career batting averages, and lots of career hits. Robin Yount is also a 2-time MVP Award winner, so if we incorporate this variabe, hopefully his prediction will become more accurate.



--------------------------------------------------

MODEL 2.0:

--------------------------------------------------

In this model, we include several more variables:

1. A categorical variable called MVP with 3 levels:
   1 = 0 career MVP awards
   2 = 1 career MVP award
   3 = 2 or more career MVP awards

2. A categorical variable for pitchers called "Cy Young Awards" with 3 levels:
   1 = 0 career Cy Young awards
   2 = 1 career Cy Young award
   3 = 2 or more career Cy Young awards

3. An indicator if the player won the Rookie of the Year award

4. An indicator if the player played for only 1 team in his career, and played for more than 2000 games with that team

Indicator variables for important milestones:
5. Over 3000 Hits (batters)
6. Over 400 Home Runs (batters)
7. Over 500 Home Runs (batters)
8. Over 300 Wins (pitchers)
9. Over 3000 Strikeouts (pitchers)

10. Last, an interaction term between batting average and years played, to see if we can produce better estimates for the high residual players from the last model, who were all high batting average players.

With this model, the rmse decreased by a tiny amount, to 0.0984. And here are our updated predictions for 2014:

18     Greg Maddux      84.1
19    Frank Thomas      67.9
20    Mike Mussina      34.0
21     Tom Glavine      57.4
22       Jeff Kent       5.5
23    Kenny Rogers       4.4
24   Luis Gonzalez       5.6
25     Moises Alou       5.8
26      Ray Durham       0.6
27      Hideo Nomo       0.1
28   Richie Sexson       0.1
29    Paul Lo Duca       0.0
30 Armando Benitez       0.9
31     Mike Timlin       0.2
32      Sean Casey       1.9
33    Jacque Jones       0.0
34      Eric Gagne       0.0
35       J.T. Snow       0.4
36      Todd Jones       0.3

Maddux is still at 84% (probably too low). Thomas and Glavine have increased, which is probably good (again, just based on our personal opinion of what voting percentage they will actually receive). And Mussina decreased by a bit. Overall, these seem somewhat realistic.

The residual plot, though, still shows some strange outliers, and many of the previously large residuals remain large:

Largest 5 residuals:

  Year          Name Actual Predicted Residual
1 2001 Kirby Puckett   82.1       4.8     77.3
2 2004  Paul Molitor   85.2      28.3     56.9
3 1999   Robin Yount   77.5      41.8     35.7
4 1999  George Brett   98.2      64.6     33.6
5 2002   Ozzie Smith   91.7      58.2     33.5

Smallest 5 residuals:

  Year          Name Actual Predicted Residual
1 2013 Roger Clemens   37.6      98.3    -60.7
2 2013   Barry Bonds   36.2      96.7    -60.5
3 2000  Jeff Reardon    4.8      62.1    -57.3
4 2000  Rich Gossage   33.3      75.5    -42.2
5 2002  Andre Dawson   45.3      86.2    -40.9


This model created a large negative residual for Jeff Reardon. For some reason, in the year 2000, based on data from 1967-1999, this model predicted that Reardon would be selected on about 62% of ballots, when in fact, he was selected on less than 5% of ballots (and this was not a surprise). It's not a good sign that the model can be off by over 50% in obvious cases like this one.


--------------------------------------------------

MODEL 3.0: Improving the fit for returning players

--------------------------------------------------

For Model 2.0, the rmse can be broken down into three groups:

First-ballot batters:      rmse = 13.5% (n = 151)
First-ballot pitchers:     rmse = 11.3% (n =  85)
Returning ballot players:  rmse =  5.7% (n = 262)

We'll focus on the third group now, by trying to come up with a better model for returning players. So far we have simply predicted that they will receive the same voting percentage as their previous year on the ballot. But on average, we know that voting percentages increase by about 1.8% each year.

We'll use the same basic tool, a regression model, to improve these predictions. For a given player appearing on his 2nd ballot or later, consider the following predictor variables:

1. Previous Year's voting percentage
2. "Trend" = Previous Year's voting percentage minus his voting percentage from two years ago (only for those on their 3rd ballot or more)
3. Number of previous ballots: a number from 1 to 14 indicating how many times the player has previously been listed on the ballot
4. "Top 3 First Ballot": The mean voting percentage of the top 3 first-ballot players in a given year. This variable we expect to have a negative association with a returning player's voting percentage, as it did in 1999, for example, when first-timers George Brett, Nolan Ryan, and Robin Yount all received very high voting percentages, and most returning players received a lower voting percentage than their previous year.

When we include these variables in a regression model on historical data to predict the current year's returning players' voting percentages, we get estimates that make sense:

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)      0.0448047  0.0048896   9.163  < 2e-16 ***
v.prev           1.0287847  0.0323198  31.831  < 2e-16 ***
I(v.prev^2)      0.1143307  0.0482606   2.369  0.01807 *  
trend           -0.1110539  0.0365387  -3.039  0.00245 ** 
bal.year        -0.0008015  0.0004570  -1.754  0.07982 .  
top3firstballot -0.0941638  0.0073194 -12.865  < 2e-16 ***

As we expected the coefficient for "Top 3 First Ballot" was negative. And there was a very strong association between the previous year's voting percentage and the current year's voting percentage. Also, the "squared", or quadratic, term for previous year's voting percentage (symbolized by "I(v.prev^2)" in the regression output above) is positive, indicating that a player "gains momentum" as his voting percentage increases toward 75%.

When we fit this model and make one-year-ahead predictions from 1997 - 2013, we find that the rmse for returning players decreases from 5.7% to 4.8%. Not bad! Nothing spectacular, but it's not bad. Interestingly, we were still unable to predict the 1999 ballot very well, because prior to 1999, we had little data to inform us of what would happen when three or more players appeared on the ballot for the first time with very high expected voting percentages. So we still have some low residuals (overpredictions) for returning players in 1999, such as Jim Rice, Steve Garvey, Tony Perez, and Gary Carter.


--------------------------------------------------

CONCLUSION

--------------------------------------------------

We'll settle on Model 3.0 as our final model (with an overall one-year-ahead rmse of 9.5%). The predcitions for the 2014 returning players will change from Model 2.0, but for first-ballot players, they'll be the same as we saw earlier. Here are the final predictions for all 36 players on the ballot, with 95% confidence interval lower and upper bounds:


              Name Prediction Lower Upper
1      Greg Maddux       84.1  78.3  88.6
2      Jack Morris       68.5  54.8  82.2
3     Craig Biggio       67.9  54.2  81.7
4     Frank Thomas       67.9  63.5  72.0
5     Jeff Bagwell       61.6  46.7  76.5
6      Mike Piazza       60.5  45.6  75.3
7      Tom Glavine       57.4  50.4  64.1
8       Tim Raines       55.0  40.1  69.8
9        Lee Smith       51.4  37.6  65.3
10  Curt Schilling       38.8  25.3  52.4
11   Roger Clemens       37.2  24.1  50.3
12     Barry Bonds       35.3  22.2  48.4
13  Edgar Martinez       35.2  22.1  48.2
14    Mike Mussina       34.0  27.2  41.5
15   Alan Trammell       33.1  20.0  46.1
16    Larry Walker       17.5   9.1  25.8
17    Fred McGriff       16.8   8.4  25.1
18    Mark McGwire       13.1   5.9  20.4
19   Don Mattingly       10.4   4.8  16.0
20      Sammy Sosa        9.3   2.9  15.7
21 Rafael Palmeiro        7.2   1.4  12.9
22     Moises Alou        5.8   5.2   6.5
23   Luis Gonzalez        5.6   4.8   6.4
24       Jeff Kent        5.5   4.7   6.4
25    Kenny Rogers        4.4   3.2   5.9
26      Sean Casey        1.9   1.6   2.1
27 Armando Benitez        0.9   0.8   1.1
28      Ray Durham        0.6   0.5   0.6
29       J.T. Snow        0.4   0.3   0.4
30      Todd Jones        0.3   0.2   0.4
31     Mike Timlin        0.2   0.1   0.3
32      Hideo Nomo        0.1   0.1   0.2
33   Richie Sexson        0.1   0.1   0.1
34    Paul Lo Duca        0.0   0.0   0.0
35    Jacque Jones        0.0   0.0   0.0
36      Eric Gagne        0.0   0.0   0.0


A few final thoughts:

1. Regarding the 95% confidence intervals: a nice check of the model will be to see whether, in fact, about 95% of the actual voting percentages are within these intervals. In other words, only about 2/36 of the actual percentages should be outside these intervals.

I expect more of the voting percentages to be outside these intervals, though, because for the first-time ballots, the intervals were calculated based on the 1967-2013 model, and are fairly narrow. That is, the intervals for first-ballot players were estimated based on the in-sample errors from the 1967-2013 model, which had an in-sample rmse of about 5%. We've seen, though, through the past 20 years, that making out-of-sample predictions is harder (with the rmse above 10% for first-ballot players). This is true because the process itself is changing, and the meaning of various statistics is changing through time (presumably mostly due to steroids, but possibly due to other factors as well). So if I were to fudge the numbers a bit, I'd inflate the intervals for first-time players by about 50%.

2. Additional useful variables would probably include the MVP voting share that players received over their lifetime. Just knowing whether they actually won the award in a given year is throwing away useful information for players who were consistently in the top-5 or top-10 of the MVP vote for their league.

3. Interestingly, using WAR, for example (a meta-statistics meant to capture all of a player's added value) didn't improve the predictions. I think this is because using all the individual statistics basically captures the same information as WAR.

4. Using other types of models didn't appear to improve things either. Random Forests (which are known to model interactions between variables well) didn't perform much better than logistic regression, and using Bayesian methods didn't change the fits of the models much (because in general, we didn't have the problem of requiring priors to rein in our parameter estimates).


Thanks to Carson Sievert, Carlos Scheidegger, and Chris Volinsky for help with code, visualization, and model suggestions.

-Kenny Shirley






http://kshirley.github.io/HOFmodel


