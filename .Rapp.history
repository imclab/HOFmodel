fit$nulldev
fit$dev.ratio
dev$lambda
fit$lambda
fit$dfmat
fit$beta[1:10]
fit$beta
xx <-  predict(fit, newdata=x[!sel, ], type="response")
p.hat <- matrix(0, n, 3)
i <- 1
sel <- data[, "fold"] != i
fit <- glmnet(x=x[sel, ], y=as.factor(data[sel, 2]), lambda=0.0025, family="multinomial")
p.hat[!sel, ] <- predict(fit, newx=x[!sel, ], type="response")
p.hat[!sel, ][1:20, ]
t1 <- Sys.time()#
p.hat <- matrix(0, n, 3)#
for (i in 1:10) {#
  sel <- data[, "fold"] != i#
  fit <- glmnet(x=x[sel, ], y=as.factor(data[sel, 2]), lambda=0.0025, family="multinomial")  #
  p.hat[!sel, ] <- predict(fit, newx=x[!sel, ], type="response")#
}#
t2 <- Sys.time()#
t2 - t1
p.hat[1:40, ]
apply(p.hat, 2, mean)
dev
cbind(1:n, match(data[, 2], c(-1, 0, 1)))[1:20,]
p.hat[1:10, ]
cbind(1:n, match(data[, 2], c(-1, 0, 1)))[1:10,]
data[1:10, 1:2]
dev.carrier <- -2*sum(log(p.hat[cbind(1:n, match(data[, 2], c(-1, 0, 1)))]))
dev.carrier
dev
500/60701
1 - dev.carrier/dev
p.hat <- as.numeric(table(data[, 2]))/n
p.hat
0.7*60000
x <- scan("ners.web.att.com/servlet/ners.viewEvent")
?lm
.13*531
.17*69
1/70
.3*330
library(ldatools)
?basicsearch.page
basicsearch.page
exp(seq(-2, -6, -0.5))
library(gmlnet)
library(glmnet)
?glmnet
library(tau)
954452/25796
data <- read.csv("~/Stats/Text/Daphne/kenny-labels-edited.csv", as.is=TRUE)
dim(data)
data[1:200, 2]
table(data[1:200, 2])
D <- max(dt[, 1])#
W <- max(dt[, 2])
?svd
load("/Users/kshirley/Stats/Text/NERS/y2.RData")
ls()
dim(y)
y[1:3, ]
1500/60
24*60
1440*24
86400/1440
60*60*30
1400/8
175*60
?segments
as.POSIXlt
as.POSIXct
?as.POSIXct
Sys.timezone()
str(OlsonNames())
OlsonNames()
200*48
200*48*90
x <- readLines("~/Stats/Text/NERS/dailytime.txt")
x[1:10]
substr(x[1], 4, 7)
count <- unlist(substr(x, 4, 7))
count[1:200]
count <- as.numeric(unlist(substr(x, 4, 7)))
count[1:100]
sum(is.na(count))
hist(count)
time <- unlist(substr(x, 9, 13))
time[1:100]
length(time)
minute <- as.numeric(unlist(substr(time, 1, 2)))*60 + as.numeric(unlist(substr(time, 4, 5)))
table(minute)
plot(minute + 1, count)
abline(v = seq(0, 1440, 60), lty=2)
200*50
263536640/1024
8873/15
600/8
lu(raw[sel, "Intrxn_id"])
colnames(ivr) <- c(ivrnames, "u1", "u2")
lu(unlist(substr(ivr[, "Ctn"], 8, 39)))
table(clarify[, "Serial_no"] %in% ivr[, "Ctn"], clarify[, "Session_start_date"])
1936/2592
rm(list=ls())#
setwd("~/Git/HOFmodel/")#
lu <- function(x) length(unique(x))#
su <- function(x) sort(unique(x))#
count.na <- function(x) sum(is.na(x))#
logit <- function(x) log(x/(1-x))#
expit <- function(x) exp(x)/(1+exp(x))
data <- read.csv(file="HOFregression.csv", as.is=TRUE)
n <- dim(data)[1]
n
dim(data)
np <- lu(data[, "Name"])
np
nb <- aggregate(data[, "NumBallots"], list(year=data[, "Year"]), median)[, 2]
nb
prev <- matrix(0, n, 14)#
for (i in 1:n) {#
  if (data[i, "YoB"] > 1) {#
    sel <- data[, "Name"] == data[i, "Name"] & data[, "YoB"] < data[i, "YoB"]#
    prev[i, 1:sum(sel)] <- data[sel, "p"][order(data[sel, "Year"], decreasing=TRUE)]#
  }#
}
colnames(prev) <- paste0("prev", 1:14)#
data <- cbind(data, prev)
AllStarpy <- data[, "all.star"]/data[, "Yrs"]#
data <- cbind(data, AllStarpy)
for (i in c("C", "1B", "2B", "3B", "SS", "LF", "CF", "RF")) assign(paste0("pos", i), as.numeric(data[, "Position"] == i))#
data <- cbind(data, posC, pos1B, pos2B, pos3B, posSS, posLF, posCF, posRF)
prev1.squared <- data[, "prev1"]^2#
data <- cbind(data, prev1.squared)
ny <- lu(data[, "Year"])#
first.ballot.crowd <- matrix(NA, ny, 5)
for (i in 1:ny) {#
  for (k in 1:5) {#
  	sel <- data[, "Year"] == su(data[, "Year"])[i] & data[, "YoB"] == 1#
  	if (i == 7) {  # special case for 1973, when Roberto Clemente was a special election:#
  	  first.ballot.crowd[i, k] <- mean(sort(data[sel & data[, "Name"] != "Roberto Clemente", "p"], decreasing=TRUE)[1:k], na.rm=TRUE)#
  	} else {#
  	  first.ballot.crowd[i, k] <- mean(sort(data[sel, "p"], decreasing=TRUE)[1:k], na.rm=TRUE)  	  #
  	}#
  }#
}#
rownames(first.ballot.crowd) <- 1967:max(data[, "Year"])
fb <- matrix(NA, n, 5)#
for (k in 1:5) fb[, k] <- first.ballot.crowd[(1:ny)[data[, "Year"] - 1966], k]#
colnames(fb) <- paste0("top", 1:5)
data <- cbind(data, fb)
return.ballot.crowd <- numeric(ny)#
for (i in 1:ny) {#
  sel <- data[, "Year"] == su(data[, "Year"])[i] - 1 & data[, "YoB"] > 1 & data[, "YoB"] < 15#
  if (sum(sel) > 0) {#
    return.ballot.crowd[i] <- mean(sort(data[sel, "p"], decreasing=TRUE)[1:5], na.rm=TRUE)#
  }#
}#
rb <- return.ballot.crowd[(1:ny)[data[, "Year"] - 1966]]
data <- cbind(data, rb)
hr500 <- as.numeric(data[, "HR"] >= 500)#
h3000 <- as.numeric(data[, "H"] >= 3000)#
w300 <- as.numeric(data[, "W"] >= 300)#
k3000 <- as.numeric(data[, "SO"] >= 3000)#
data <- cbind(data, hr500, h3000, w300, k3000)#
#
# Create indicator variables for 2nd ballot and 15th ballot (players are thought to get an extra bump #
# in these two situations)#
ballot2 <- as.numeric(data[, "YoB"] == 2)#
ballotfinal <- as.numeric(data[, "YoB"] == 15)#
data <- cbind(data, ballot2, ballotfinal)#
#
ballot2.x.prev1 <- data[, "ballot2"]*data[, "prev1"]  # Interaction between 2nd year and 1st year percentage#
data <- cbind(data, ballot2.x.prev1)
type <- numeric(n)
type[data[, "Position"] != "P" & data[, "YoB"] == 1] <- 1#
#
# Type 2 = First-ballot pitchers:#
type[data[, "Position"] == "P" & data[, "YoB"] == 1] <- 2#
#
# Type 3 = 2nd or more time on ballot:#
type[data[, "YoB"] > 1] <- 3#
#
# total number of different types (this changed a few times as I tried different models)#
nt <- lu(type)#
#
# Set up list to hold names of variables to include in the regression model for each type:#
var.names <- as.list(rep(NA, nt))
var.names[[1]] <- c("Yrs", "G", "AB", "R", "H", "HR", "RBI", "SB", "BB", "BA", "OBP", "SLG",#
                    "posC", "pos1B", "pos2B", "pos3B", "posSS", "posLF", "posCF", "posRF")#
var.names[[2]] <- c("Yrs", "W", "L", "ERA", "WHIP", "G.1", "GS", "SV", "IP", "H.1", "HR.1", "BB.1", "SO")#
var.names[[3]] <- c("prev1")  # for returning players, just use the previous year's voting percentage as the sole predictor
pred <- rep(NA, n)#
pred.mat <- matrix(NA, n, 5)#
qbounds <- function(x) quantile(x, c(0.025, 0.250, 0.500, 0.750, 0.975))
coef <- as.list(rep(NA, nt))#
lt <- length(1997:max(data[, "Year"]))#
for (j in 1:nt){#
  coef[[j]] <- matrix(NA, lt, length(var.names[[j]]) + 1)#
  colnames(coef[[j]]) <- c("Intercept", var.names[[j]])#
  rownames(coef[[j]]) <- 1997:max(data[, "Year"])#
}
in.samp <- matrix(NA, lt, nt)
for (t in 1997:max(data[, "Year"])) {#
  print(t)#
  for (j in 1:nt) {#
#
    # Set up the design matrix for this type of prediction:#
    if (j %in% 1:2) sel <- type == j & data[, "Year"] < t#
    if (j > 2) sel <- type == j & data[, "Year"] < t & data[, "prev1"] >= 0.05#
    X.mat <- as.matrix(data[sel, var.names[[j]]])#
#
    # Scale the inputs, keeping the means and sds:#
    x.mean <- apply(X.mat, 2, mean)#
    x.sd <- apply(X.mat, 2, sd)#
    X.scale <- X.mat#
    for (i in 1:dim(X.mat)[2]) {#
      if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
    }#
    # Fit the model using weak priors:#
    fit <- bayesglm(data[sel, "p"] ~ X.scale, weights=data[sel, "NumBallots"], family=binomial(link = "logit"), #
                    prior.mean=0, prior.scale=2.5)#
    in.samp[t - 1996, j] <- sd(fit$fitted.values - data[sel, "p"])#
    # Store the coefficients:#
    coef[[j]][t - 1996, ] <- coef(fit)#
#
    # predict this type for the year of interest:#
    sel.test <- type == j & data[, "Year"] == t#
#
    if (sum(sel.test) > 0) {#
      X.mat <- as.matrix(data[sel.test, var.names[[j]]])#
      if (t > 2013 & j == 3 & "top3" %in% var.names[[j]]) {#
      	X.mat[, "top3"] <- mean(sort(pred[data[, "Year"] == t & type %in% 1:2], decreasing=TRUE)[1:3], na.rm=TRUE)#
      }#
      X.scale <- X.mat#
      for (i in 1:dim(X.mat)[2]) {#
        if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
      }#
      beta <- mvrnorm(1000, mu=coef(fit), Sigma=summary(fit)$cov.scaled)#
      pred[sel.test] <- expit(coef(fit)[1] + X.scale %*% matrix(coef(fit)[-1], ncol=1))#
      pred.sim <- expit(beta[,1] + X.scale %*% t(beta[, -1]))#
      votes.sim <- matrix(rbinom(sum(sel.test)*1000, size=nb[t - 1966], prob=pred.sim), sum(sel.test), 1000)/nb[t - 1966]#
      pred.mat[sel.test, ] <- t(apply(votes.sim, 1, qbounds))#
    }#
  }#
}
install.packages("arm")
library(arm)
for (t in 1997:max(data[, "Year"])) {#
  print(t)#
  for (j in 1:nt) {#
#
    # Set up the design matrix for this type of prediction:#
    if (j %in% 1:2) sel <- type == j & data[, "Year"] < t#
    if (j > 2) sel <- type == j & data[, "Year"] < t & data[, "prev1"] >= 0.05#
    X.mat <- as.matrix(data[sel, var.names[[j]]])#
#
    # Scale the inputs, keeping the means and sds:#
    x.mean <- apply(X.mat, 2, mean)#
    x.sd <- apply(X.mat, 2, sd)#
    X.scale <- X.mat#
    for (i in 1:dim(X.mat)[2]) {#
      if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
    }#
    # Fit the model using weak priors:#
    fit <- bayesglm(data[sel, "p"] ~ X.scale, weights=data[sel, "NumBallots"], family=binomial(link = "logit"), #
                    prior.mean=0, prior.scale=2.5)#
    in.samp[t - 1996, j] <- sd(fit$fitted.values - data[sel, "p"])#
    # Store the coefficients:#
    coef[[j]][t - 1996, ] <- coef(fit)#
#
    # predict this type for the year of interest:#
    sel.test <- type == j & data[, "Year"] == t#
#
    if (sum(sel.test) > 0) {#
      X.mat <- as.matrix(data[sel.test, var.names[[j]]])#
      if (t > 2013 & j == 3 & "top3" %in% var.names[[j]]) {#
      	X.mat[, "top3"] <- mean(sort(pred[data[, "Year"] == t & type %in% 1:2], decreasing=TRUE)[1:3], na.rm=TRUE)#
      }#
      X.scale <- X.mat#
      for (i in 1:dim(X.mat)[2]) {#
        if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
      }#
      beta <- mvrnorm(1000, mu=coef(fit), Sigma=summary(fit)$cov.scaled)#
      pred[sel.test] <- expit(coef(fit)[1] + X.scale %*% matrix(coef(fit)[-1], ncol=1))#
      pred.sim <- expit(beta[,1] + X.scale %*% t(beta[, -1]))#
      votes.sim <- matrix(rbinom(sum(sel.test)*1000, size=nb[t - 1966], prob=pred.sim), sum(sel.test), 1000)/nb[t - 1966]#
      pred.mat[sel.test, ] <- t(apply(votes.sim, 1, qbounds))#
    }#
  }#
}
sel.pred <- data[, "Year"] > 1996 & data[, "Year"] < 2015
rmse <- sqrt(mean((pred[sel.pred] - data[sel.pred, "p"])^2))
rmse
rmse.vec <- numeric(nt)#
sel.vec <- as.list(rep(NA, nt))#
for (j in 1:3) sel.vec[[j]] <- sel.pred & type == j#
for (i in 1:nt) rmse.vec[i] <- sqrt(mean((pred[sel.vec[[i]]] - data[sel.vec[[i]], "p"])^2))
rmse.vec
out.samp <- matrix(NA, lt, 3)#
n.out <- matrix(NA, lt, 3)#
for (i in 1:lt) {#
  for (j in 1:3) {#
  	sel <- data[, "Year"] == i + 1996 & type == j#
  	out.samp[i, j] <- sd(pred[sel] - data[sel, "p"])#
  	n.out[i, j] <- sum(sel)#
  }#
}
n.out
par(mfrow=c(1, 3))#
for (j in 1:3) {#
  plot(1997:max(data[, "Year"]), in.samp[, j], type="l", ylim=range(c(in.samp[, j], out.samp[-lt, j])), #
       las=1, ylab="RMSE", xlab="Year")#
  lines(1997:(max(data[, "Year"]) - 1), out.samp[-lt, j], lty=2)#
}
resids <- data[sel.pred, "p"] - pred[sel.pred]
sel.big <- abs(resids) > 0.1  # select big residuals to display names#
xl <- "Predicted Percentage"
par(mfrow=c(1, 1))#
plot(pred[sel.pred], resids, type="n", las=1, ylab="Actual Vote % - Predicted Vote %", yaxt="n", xlim=c(0, 1.1), xlab=xl, xaxt="n")#
axis(2, at=seq(-1, 1, 0.2), labels=paste(seq(-100, 100, 20), "%", sep=""), las=1)#
axis(1, at=seq(0, 1, 0.2), labels=paste0(seq(0, 100, 20), "%"))#
abline(h=seq(-1, 1, 0.1), col=gray(0.8))#
text(pred[sel.pred][sel.big], resids[sel.big], paste(data[sel.pred, "Name"], #
     data[sel.pred, "Year"], sep="-")[sel.big], cex=0.6, col=as.numeric(data[sel.pred, "YoB"][sel.big] == 1) + 1)#
points(pred[sel.pred][!sel.big], resids[!sel.big], col=as.numeric(data[sel.pred, "YoB"][!sel.big] == 1) + 1)#
legend("topright", inset=0.01, col=c(1, 2), pch=19, legend=c("Returning Player", "First Ballot"))
rmse
rmse[sel.pred]
rm(list=ls())#
setwd("~/Git/HOFmodel/")#
lu <- function(x) length(unique(x))#
su <- function(x) sort(unique(x))#
count.na <- function(x) sum(is.na(x))#
logit <- function(x) log(x/(1-x))#
expit <- function(x) exp(x)/(1+exp(x))#
#
# Load a library to do Bayesian generalized linear models:
data <- read.csv(file="HOFregression.csv", as.is=TRUE)#
n <- dim(data)[1]
dim(data)
data[, 1:10]
data[1:10, ]
np <- lu(data[, "Name"])
nb <- aggregate(data[, "NumBallots"], list(year=data[, "Year"]), median)[, 2]
nb
length(nb)
prev <- matrix(0, n, 14)#
for (i in 1:n) {#
  if (data[i, "YoB"] > 1) {#
    sel <- data[, "Name"] == data[i, "Name"] & data[, "YoB"] < data[i, "YoB"]#
    prev[i, 1:sum(sel)] <- data[sel, "p"][order(data[sel, "Year"], decreasing=TRUE)]#
  }#
}#
colnames(prev) <- paste0("prev", 1:14)#
data <- cbind(data, prev)
AllStarpy <- data[, "all.star"]/data[, "Yrs"]#
data <- cbind(data, AllStarpy)
for (i in c("C", "1B", "2B", "3B", "SS", "LF", "CF", "RF")) assign(paste0("pos", i), as.numeric(data[, "Position"] == i))#
data <- cbind(data, posC, pos1B, pos2B, pos3B, posSS, posLF, posCF, posRF)#
#
# Add in previous year's vote squared#
prev1.squared <- data[, "prev1"]^2#
data <- cbind(data, prev1.squared)#
#
# Add the mean vote percentage of the top-k (k = 1, 2, 3, 4, 5) first-year ballot players in each year:#
# Idea is that this will provide a variable to account for 'crowded' ballots:#
ny <- lu(data[, "Year"])#
first.ballot.crowd <- matrix(NA, ny, 5)#
for (i in 1:ny) {#
  for (k in 1:5) {#
  	sel <- data[, "Year"] == su(data[, "Year"])[i] & data[, "YoB"] == 1#
  	if (i == 7) {  # special case for 1973, when Roberto Clemente was a special election:#
  	  first.ballot.crowd[i, k] <- mean(sort(data[sel & data[, "Name"] != "Roberto Clemente", "p"], decreasing=TRUE)[1:k], na.rm=TRUE)#
  	} else {#
  	  first.ballot.crowd[i, k] <- mean(sort(data[sel, "p"], decreasing=TRUE)[1:k], na.rm=TRUE)  	  #
  	}#
  }#
}#
rownames(first.ballot.crowd) <- 1967:max(data[, "Year"])#
#
fb <- matrix(NA, n, 5)#
for (k in 1:5) fb[, k] <- first.ballot.crowd[(1:ny)[data[, "Year"] - 1966], k]#
colnames(fb) <- paste0("top", 1:5)#
#
# Append these to the data:#
data <- cbind(data, fb)#
#
# Add the mean vote percentage of the top-5 returning ballot players in each year:#
return.ballot.crowd <- numeric(ny)#
for (i in 1:ny) {#
  sel <- data[, "Year"] == su(data[, "Year"])[i] - 1 & data[, "YoB"] > 1 & data[, "YoB"] < 15#
  if (sum(sel) > 0) {#
    return.ballot.crowd[i] <- mean(sort(data[sel, "p"], decreasing=TRUE)[1:5], na.rm=TRUE)#
  }#
}#
rb <- return.ballot.crowd[(1:ny)[data[, "Year"] - 1966]]#
#
# Append these to the data:#
data <- cbind(data, rb)#
#
# add a few career milestones that are thought to impact HOF voting:#
hr500 <- as.numeric(data[, "HR"] >= 500)#
h3000 <- as.numeric(data[, "H"] >= 3000)#
w300 <- as.numeric(data[, "W"] >= 300)#
k3000 <- as.numeric(data[, "SO"] >= 3000)#
data <- cbind(data, hr500, h3000, w300, k3000)#
#
# Create indicator variables for 2nd ballot and 15th ballot (players are thought to get an extra bump #
# in these two situations)#
ballot2 <- as.numeric(data[, "YoB"] == 2)#
ballotfinal <- as.numeric(data[, "YoB"] == 15)#
data <- cbind(data, ballot2, ballotfinal)#
#
ballot2.x.prev1 <- data[, "ballot2"]*data[, "prev1"]  # Interaction between 2nd year and 1st year percentage#
data <- cbind(data, ballot2.x.prev1)
type <- numeric(n)#
#
# Type 1 = First-ballot batters:#
type[data[, "Position"] != "P" & data[, "YoB"] == 1] <- 1#
#
# Type 2 = First-ballot pitchers:#
type[data[, "Position"] == "P" & data[, "YoB"] == 1] <- 2#
#
# Type 3 = 2nd or more time on ballot:#
type[data[, "YoB"] > 1] <- 3#
#
# total number of different types (this changed a few times as I tried different models)#
nt <- lu(type)#
#
# Set up list to hold names of variables to include in the regression model for each type:#
var.names <- as.list(rep(NA, nt))
var.names[[1]] <- c("Yrs", "G", "AB", "R", "H", "HR", "RBI", "SB", "BB", "BA", "OBP", "SLG",#
                    "posC", "pos1B", "pos2B", "pos3B", "posSS", "posLF", "posCF", "posRF")#
var.names[[2]] <- c("Yrs", "W", "L", "ERA", "WHIP", "G.1", "GS", "SV", "IP", "H.1", "HR.1", "BB.1", "SO")#
var.names[[3]] <- c("prev1")  # for returning players, just use the previous year's voting percentage as the sole predictor
pred <- rep(NA, n)#
pred.mat <- matrix(NA, n, 5)#
qbounds <- function(x) quantile(x, c(0.025, 0.250, 0.500, 0.750, 0.975))
coef <- as.list(rep(NA, nt))#
lt <- length(1997:max(data[, "Year"]))#
for (j in 1:nt){#
  coef[[j]] <- matrix(NA, lt, length(var.names[[j]]) + 1)#
  colnames(coef[[j]]) <- c("Intercept", var.names[[j]])#
  rownames(coef[[j]]) <- 1997:max(data[, "Year"])#
}
in.samp <- matrix(NA, lt, nt)
t <- 1997
j <- 1
nt
if (j %in% 1:2) sel <- type == j & data[, "Year"] < t#
    if (j > 2) sel <- type == j & data[, "Year"] < t & data[, "prev1"] >= 0.05#
    X.mat <- as.matrix(data[sel, var.names[[j]]])
x.mean <- apply(X.mat, 2, mean)#
    x.sd <- apply(X.mat, 2, sd)#
    X.scale <- X.mat#
    for (i in 1:dim(X.mat)[2]) {#
      if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
    }
x.mean
x.sd
fit <- bayesglm(data[sel, "p"] ~ X.scale, weights=data[sel, "NumBallots"], family=binomial(link = "logit"), #
                    prior.mean=0, prior.scale=2.5)
summary(fit)
in.samp[t - 1996, j] <- sd(fit$fitted.values - data[sel, "p"])
coef[[j]][t - 1996, ] <- coef(fit)
sel.test <- type == j & data[, "Year"] == t
if (sum(sel.test) > 0) {#
      X.mat <- as.matrix(data[sel.test, var.names[[j]]])#
      if (t > 2013 & j == 3 & "top3" %in% var.names[[j]]) {#
      	X.mat[, "top3"] <- mean(sort(pred[data[, "Year"] == t & type %in% 1:2], decreasing=TRUE)[1:3], na.rm=TRUE)#
      }#
      X.scale <- X.mat#
      for (i in 1:dim(X.mat)[2]) {#
        if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
      }#
      beta <- mvrnorm(1000, mu=coef(fit), Sigma=summary(fit)$cov.scaled)#
      pred[sel.test] <- expit(coef(fit)[1] + X.scale %*% matrix(coef(fit)[-1], ncol=1))#
      pred.sim <- expit(beta[,1] + X.scale %*% t(beta[, -1]))#
      votes.sim <- matrix(rbinom(sum(sel.test)*1000, size=nb[t - 1966], prob=pred.sim), sum(sel.test), 1000)/nb[t - 1966]#
      pred.mat[sel.test, ] <- t(apply(votes.sim, 1, qbounds))#
    }
pred.mat[sel.test, ]
for (t in 1997:max(data[, "Year"])) {#
  print(t)#
  for (j in 1:nt) {#
#
    # Set up the design matrix for this type of prediction:#
    if (j %in% 1:2) sel <- type == j & data[, "Year"] < t#
    if (j > 2) sel <- type == j & data[, "Year"] < t & data[, "prev1"] >= 0.05#
    X.mat <- as.matrix(data[sel, var.names[[j]]])#
#
    # Scale the inputs, keeping the means and sds:#
    x.mean <- apply(X.mat, 2, mean)#
    x.sd <- apply(X.mat, 2, sd)#
    X.scale <- X.mat#
    for (i in 1:dim(X.mat)[2]) {#
      if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
    }#
    # Fit the model using weak priors:#
    fit <- bayesglm(data[sel, "p"] ~ X.scale, weights=data[sel, "NumBallots"], family=binomial(link = "logit"), #
                    prior.mean=0, prior.scale=2.5)#
    in.samp[t - 1996, j] <- sd(fit$fitted.values - data[sel, "p"])#
    # Store the coefficients:#
    coef[[j]][t - 1996, ] <- coef(fit)#
#
    # predict this type for the year of interest:#
    sel.test <- type == j & data[, "Year"] == t#
#
    if (sum(sel.test) > 0) {#
      X.mat <- as.matrix(data[sel.test, var.names[[j]]])#
      if (t > 2013 & j == 3 & "top3" %in% var.names[[j]]) {#
      	X.mat[, "top3"] <- mean(sort(pred[data[, "Year"] == t & type %in% 1:2], decreasing=TRUE)[1:3], na.rm=TRUE)#
      }#
      X.scale <- X.mat#
      for (i in 1:dim(X.mat)[2]) {#
        if (x.sd[i] != 0) X.scale[, i] <- (X.mat[, i] - x.mean[i])/x.sd[i]#
      }#
      beta <- mvrnorm(1000, mu=coef(fit), Sigma=summary(fit)$cov.scaled)#
      pred[sel.test] <- expit(coef(fit)[1] + X.scale %*% matrix(coef(fit)[-1], ncol=1))#
      pred.sim <- expit(beta[,1] + X.scale %*% t(beta[, -1]))#
      votes.sim <- matrix(rbinom(sum(sel.test)*1000, size=nb[t - 1966], prob=pred.sim), sum(sel.test), 1000)/nb[t - 1966]#
      pred.mat[sel.test, ] <- t(apply(votes.sim, 1, qbounds))#
    }#
  }#
}
sel.pred <- data[, "Year"] > 1996 & data[, "Year"] < 2015
rmse <- sqrt(mean((pred[sel.pred] - data[sel.pred, "p"])^2))
rmse
pred
length(pred)
sel.pred
which(sel.pred)
pred[sel.pred]
data[sel.pred, "p"]
data[1:20, ]
sel.pred <- data[, "Year"] > 1996 & data[, "Year"] < 2014#
rmse <- sqrt(mean((pred[sel.pred] - data[sel.pred, "p"])^2))
rmse
rmse.vec <- numeric(nt)#
sel.vec <- as.list(rep(NA, nt))#
for (j in 1:3) sel.vec[[j]] <- sel.pred & type == j#
for (i in 1:nt) rmse.vec[i] <- sqrt(mean((pred[sel.vec[[i]]] - data[sel.vec[[i]], "p"])^2))
rmse.vec
out.samp <- matrix(NA, lt, 3)#
n.out <- matrix(NA, lt, 3)#
for (i in 1:lt) {#
  for (j in 1:3) {#
  	sel <- data[, "Year"] == i + 1996 & type == j#
  	out.samp[i, j] <- sd(pred[sel] - data[sel, "p"])#
  	n.out[i, j] <- sum(sel)#
  }#
}
par(mfrow=c(1, 3))#
for (j in 1:3) {#
  plot(1997:max(data[, "Year"]), in.samp[, j], type="l", ylim=range(c(in.samp[, j], out.samp[-lt, j])), #
       las=1, ylab="RMSE", xlab="Year")#
  lines(1997:(max(data[, "Year"]) - 1), out.samp[-lt, j], lty=2)#
}
resids <- data[sel.pred, "p"] - pred[sel.pred]
sel.big <- abs(resids) > 0.1  # select big residuals to display names#
xl <- "Predicted Percentage"
par(mfrow=c(1, 1))#
plot(pred[sel.pred], resids, type="n", las=1, ylab="Actual Vote % - Predicted Vote %", yaxt="n", xlim=c(0, 1.1), xlab=xl, xaxt="n")#
axis(2, at=seq(-1, 1, 0.2), labels=paste(seq(-100, 100, 20), "%", sep=""), las=1)#
axis(1, at=seq(0, 1, 0.2), labels=paste0(seq(0, 100, 20), "%"))#
abline(h=seq(-1, 1, 0.1), col=gray(0.8))#
text(pred[sel.pred][sel.big], resids[sel.big], paste(data[sel.pred, "Name"], #
     data[sel.pred, "Year"], sep="-")[sel.big], cex=0.6, col=as.numeric(data[sel.pred, "YoB"][sel.big] == 1) + 1)#
points(pred[sel.pred][!sel.big], resids[!sel.big], col=as.numeric(data[sel.pred, "YoB"][!sel.big] == 1) + 1)#
legend("topright", inset=0.01, col=c(1, 2), pch=19, legend=c("Returning Player", "First Ballot"))
cover50 <- numeric(nt)#
cover95 <- numeric(nt)#
for (j in 1:nt) {#
  s <- sel.pred & type == j#
  cover50[j] <- sum(data[s, "p"] > pred.mat[s, 2] & data[s, "p"] < pred.mat[s, 4])/sum(s)#
  cover95[j] <- sum(data[s, "p"] > pred.mat[s, 1] & data[s, "p"] < pred.mat[s, 5])/sum(s)#
}
cover50
cover95
sel1997 <- data[, "Year"] == 1997 & type == 1#
d1997 <- data.frame(Name=data[sel1997, "Name"], Prediction=round(pred[sel1997], 3)*100, Actual=round(data[sel1997, "p"], 3)*100)#
#
# 1997 batters rmse:#
sqrt(mean((d1997[, 2] - d1997[, 3])^2))
sel2014 <- data[, "Year"] == 2014#
d2014 <- data.frame(Name=data[sel2014, "Name"], Previous=round(data[sel2014, "prev1"], 3)*100, #
                    Predicted=round(pred[sel2014], 3)*100)
d2014 <- d2014[order(d2014[, "Predicted"], decreasing=TRUE), ]#
rownames(d2014) <- 1:dim(d2014)[1]
d2014
first2014 <- d2014[d2014[, 2] == 0, ]#
rownames(first2014) <- 1:dim(first2014)[1]
first2014
library(knitr)
install.packages("knitr")
library(knitr)
getwd()
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
install.packages("ggplot2")
library(ggplot2)
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
library(ggplot2)
library(ggplot)
qplot(1:10, 1:10)
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
dim(Data)
dim(data)
data[1:10, ]
data[data[, "Votes"] == 0 & data[, "YoB"] == 1, ][1:50, ]
data[data[, "Votes"] == 0 & data[, "YoB"] == 1, ][1:100, 1:10]
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
data[data[, "Votes"] == 1 & data[, "YoB"] == 1, ][1:100, 1:10]
data[data[, "Votes"] == 0 & data[, "YoB"] == 1, ][1:100, 1:10]
data[63, ]
data[data[, 1] == "Jeromy Burnitz", ]
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
knit("HOF_vis_model.Rmd")
dim(data)
data[1:10, ]
data[1:10, 1:5]
data[, 2]
lu(data[, 1])
